{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import collections\n",
    "from time import sleep\n",
    "from functools import wraps\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(f'Function {func.__name__} {args} Took {total_time:.4f} seconds')\n",
    "        return result\n",
    "    return timeit_wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deezer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base URL for the Deezer API\n",
    "base_url = \"https://api.deezer.com/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_genre(album_id):\n",
    "    list_genres = []\n",
    "    album_url = f\"https://api.deezer.com/album/{album_id}\"\n",
    "    album_data = requests.get(album_url)\n",
    "    album_data = album_data.json()\n",
    "    for genre in album_data['genres']['data']:\n",
    "        list_genres.append(genre['name'])\n",
    "    return list_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_genres(title, artist):# Set the search query\n",
    "    query = f\"{title}\t{artist}\"\n",
    "\n",
    "    # Set the parameters for the request\n",
    "    params = { \"q\": query, \"limit\": 1}\n",
    "\n",
    "    # Send the request to the Deezer API\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    try:\n",
    "        track = data['data'][0]\n",
    "        genres = get_album_genre(track['album']['id'])\n",
    "\n",
    "    except (IndexError, KeyError):\n",
    "        return []\n",
    "\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_additional_infos(title, artist):# Set the search query\n",
    "    query = f\"{title}\t{artist}\"\n",
    "\n",
    "    # Set the parameters for the request\n",
    "    params = { \"q\": query, \"limit\": 1}\n",
    "\n",
    "    # Send the request to the Deezer API\n",
    "    response = requests.get(base_url, params=params)\n",
    "\n",
    "    data = response.json()\n",
    "    try:\n",
    "        track = data['data'][0]\n",
    "        track_infos = dict()\n",
    "        track_infos['explicit_lyrics'] = 1 if bool(track['explicit_lyrics']) else 0\n",
    "        track_infos['duration'] = int(track['duration'])\n",
    "        track_infos['genres'] = get_album_genre(track['album']['id'])\n",
    "\n",
    "    except (IndexError, KeyError):\n",
    "        track_infos = dict()\n",
    "        track_infos['explicit_lyrics'] = None\n",
    "        track_infos['duration'] = None\n",
    "        track_infos['genres'] = []\n",
    "\n",
    "    return track_infos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOT100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = r\"C:/Users/Aymeric Leboucher/OneDrive - De Vinci/ESILV/A5/Webscrapping/TP2/chromedriver.exe\"\n",
    "chromedriver_path_erget = r\"C:/Users/AymericLEBOUCHER/OneDrive - Groupe ERGET/Ressources/ESILV/Webscrapping/chromedriver_win32/chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_source(link, driver):\n",
    "    driver.get(link)\n",
    "    src=driver.page_source\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_parser(page):\n",
    "    parser = BeautifulSoup(page, \"lxml\")\n",
    "    table = parser.find(\"div\", attrs={\"class\":\"chart-results-list // lrv-u-padding-t-150 lrv-u-padding-t-050@mobile-max\"})\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_from_song_titles = [ 'Imprint/Promotion Label:',\n",
    " 'Songwriter(s):',\n",
    " 'Producer(s):']\n",
    "\n",
    "def extract_song_titles(table):\n",
    "    song_titles = table.find_all(\"h3\")\n",
    "    ori_songlist = [h.text.strip() for h in song_titles[2:]]\n",
    "    songlist = [word for word in ori_songlist if word not in to_remove_from_song_titles]\n",
    "    return songlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_artists(table):\n",
    "    to_remove_from_artists = [\"\",'Share Chart on Twitter','Share Chart on Embed', 'This Week',\n",
    "                            'Award',\n",
    "                            'Last Week',\n",
    "                            'Peak Pos.',\n",
    "                            'Wks on Chart',\n",
    "                            'Twitter',\n",
    "                            'Share Chart on Copy Link',\n",
    "                            'Copy Link',\n",
    "                            'Share Chart on Facebook',\n",
    "                            'Facebook',\n",
    "                            'Embed',\n",
    "                            'RIAA Certification:',\n",
    "                            'Diamond',\n",
    "                            \"Platinum\",\n",
    "                            'Platinum x2',\n",
    "                            'Platinum x3',\n",
    "                            'Platinum x4',\n",
    "                            'Platinum x5',\n",
    "                            'Platinum x6',\n",
    "                            'Platinum x7',\n",
    "                            'Platinum x8',\n",
    "                            'Platinum x9',\n",
    "                            'RE-\\nENTRY',\n",
    "                            'Gold',\n",
    "                            'NEW',\n",
    "                            \"-\"]\n",
    "\n",
    "    artists = table.find_all(\"span\")\n",
    "    artists = [h.text.strip() for h in artists]\n",
    "    artists = [artists[i] for i in range(len(artists)) if artists[i] not in to_remove_from_artists if not artists[i].isdigit()]\n",
    "    return artists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_top_100(songlist, artists):\n",
    "    top_100 = pd.concat([pd.Series(songlist), pd.Series(artists)], axis=1)\n",
    "    top_100.rename(columns = {0:\"title\", 1:\"artist\"}, inplace=True)\n",
    "    return top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_infos(row):\n",
    "    track_infos = get_track_additional_infos(row.title, row.artist)\n",
    "    row.genres = track_infos[\"genres\"]\n",
    "    row.duration = track_infos['duration']\n",
    "    row.explicit_content = track_infos['explicit_lyrics']\n",
    "    return row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genres(row):\n",
    "    row.genres = get_track_genres(row.title, row.artist)\n",
    "    return row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = ChromeService(executable_path=chromedriver_path)\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('-headless')\n",
    "\n",
    "@timeit\n",
    "def get_top_100(year, month, day, service=service, verbose=0, additional=False):\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    month = str(month)\n",
    "    if len(month)==1:\n",
    "        month = \"0\" + month\n",
    "    day = str(day)\n",
    "    if len(day)==1:\n",
    "        day = \"0\" + day\n",
    "    link = f\"https://www.billboard.com/charts/hot-100/{year}-{month}-{day}/\"\n",
    "    src = get_page_source(link, driver)\n",
    "    table = page_parser(src)\n",
    "    songlist = extract_song_titles(table)\n",
    "    artists = extract_artists(table)\n",
    "    top_100 = convert_to_top_100(songlist, artists)\n",
    "    top_100['genres'] = None\n",
    "    if additional:\n",
    "        top_100['duration'] = None\n",
    "        top_100['explicit_content'] = None\n",
    "        top_100 = top_100.apply(additional_infos, axis=1)\n",
    "    else: \n",
    "        top_100 = top_100.apply(genres, axis=1)\n",
    "    if verbose==1:\n",
    "        freq = collections.Counter(top_100.genres.sum())\n",
    "        return top_100, dict(sorted(freq.items(), key=lambda x: x[1], reverse=True))\n",
    "    return top_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_100(1989, 2, 1, additional=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOT100 Generator with Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annee in range(1978, 2022):\n",
    "    for month in range(1, 13):\n",
    "        top_100, top_style = get_top_100(annee, month, 1, verbose=1, additional=True)\n",
    "        print(\"Top style: \", list(top_style.keys())[0])\n",
    "        top_100.to_csv(f\"C:/Users/AymericLEBOUCHER/OneDrive - Groupe ERGET/Ressources/ESILV/Webscrapping/month_top_100/{annee}-{month}.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cac6ca5711206a852d0002262a3b61d4dce708efe823e1adadf1f1c08297907"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
